{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential Statistics Ia - Frequentism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the first Frequentist inference mini-project! Over the course of working on this mini-project and the next frequentist mini-project, you'll learn the fundamental concepts associated with frequentist inference. The following list includes the topics you will become familiar with as you work through these two mini-projects:\n",
    "* the _z_-statistic\n",
    "* the _t_-statistic\n",
    "* the difference and relationship between the two\n",
    "* the Central Limit Theorem, including its assumptions and consequences\n",
    "* how to estimate the population mean and standard deviation from a sample\n",
    "* the concept of a sampling distribution of a test statistic, particularly for the mean\n",
    "* how to combine these concepts to calculate a confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For working through this notebook, you are expected to have a very basic understanding of:\n",
    "* what a random variable is\n",
    "* what a probability density function (pdf) is\n",
    "* what the cumulative density function is\n",
    "* a high-level sense of what the Normal distribution\n",
    "\n",
    "If these concepts are new to you, please take a few moments to Google these topics in order to get a sense of what they are and how you might use them.\n",
    "\n",
    "While it's great if you have previous knowledge about sampling distributions, this assignment will introduce the concept and set you up to practice working using sampling distributions. This notebook was designed to bridge the gap between having a basic understanding of probability and random variables and being able to apply these concepts in Python. The second frequentist inference mini-project focuses on a real-world application of this type of inference to give you further practice using these concepts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we will use data sampled from a known normal distribution. This allows us to compare our results with theoretical expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I An introduction to sampling from the Normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's explore the ways we can generate the Normal distribution. While there's a fair amount of interest in [sklearn](https://scikit-learn.org/stable/) within the machine learning community, you're likely to have heard of [scipy](https://docs.scipy.org/doc/scipy-0.15.1/reference/index.html) if you're coming from the sciences. For this assignment, you'll use [scipy.stats](https://docs.scipy.org/doc/scipy-0.15.1/reference/tutorial/stats.html) to complete your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Call up the doc for norm. What is the second listed method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on norm_gen in module scipy.stats._continuous_distns object:\n",
      "\n",
      "class norm_gen(scipy.stats._distn_infrastructure.rv_continuous)\n",
      " |  A normal continuous random variable.\n",
      " |  \n",
      " |  The location (loc) keyword specifies the mean.\n",
      " |  The scale (scale) keyword specifies the standard deviation.\n",
      " |  \n",
      " |  %(before_notes)s\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The probability density function for `norm` is::\n",
      " |  \n",
      " |      norm.pdf(x) = exp(-x**2/2)/sqrt(2*pi)\n",
      " |  \n",
      " |  The survival function, ``norm.sf``, is also referred to as the\n",
      " |  Q-function in some contexts (see, e.g.,\n",
      " |  `Wikipedia's <https://en.wikipedia.org/wiki/Q-function>`_ definition).\n",
      " |  \n",
      " |  %(after_notes)s\n",
      " |  \n",
      " |  %(example)s\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      norm_gen\n",
      " |      scipy.stats._distn_infrastructure.rv_continuous\n",
      " |      scipy.stats._distn_infrastructure.rv_generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  fit(self, data, **kwds)\n",
      " |      Return MLEs for shape (if applicable), location, and scale\n",
      " |      parameters from data.\n",
      " |      \n",
      " |      MLE stands for Maximum Likelihood Estimate.  Starting estimates for\n",
      " |      the fit are given by input arguments; for any arguments not provided\n",
      " |      with starting estimates, ``self._fitstart(data)`` is called to generate\n",
      " |      such.\n",
      " |      \n",
      " |      One can hold some parameters fixed to specific values by passing in\n",
      " |      keyword arguments ``f0``, ``f1``, ..., ``fn`` (for shape parameters)\n",
      " |      and ``floc`` and ``fscale`` (for location and scale parameters,\n",
      " |      respectively).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : array_like\n",
      " |          Data to use in calculating the MLEs.\n",
      " |      args : floats, optional\n",
      " |          Starting value(s) for any shape-characterizing arguments (those not\n",
      " |          provided will be determined by a call to ``_fitstart(data)``).\n",
      " |          No default value.\n",
      " |      kwds : floats, optional\n",
      " |          Starting values for the location and scale parameters; no default.\n",
      " |          Special keyword arguments are recognized as holding certain\n",
      " |          parameters fixed:\n",
      " |      \n",
      " |          - f0...fn : hold respective shape parameters fixed.\n",
      " |            Alternatively, shape parameters to fix can be specified by name.\n",
      " |            For example, if ``self.shapes == \"a, b\"``, ``fa``and ``fix_a``\n",
      " |            are equivalent to ``f0``, and ``fb`` and ``fix_b`` are\n",
      " |            equivalent to ``f1``.\n",
      " |      \n",
      " |          - floc : hold location parameter fixed to specified value.\n",
      " |      \n",
      " |          - fscale : hold scale parameter fixed to specified value.\n",
      " |      \n",
      " |          - optimizer : The optimizer to use.  The optimizer must take ``func``,\n",
      " |            and starting position as the first two arguments,\n",
      " |            plus ``args`` (for extra arguments to pass to the\n",
      " |            function to be optimized) and ``disp=0`` to suppress\n",
      " |            output as keyword arguments.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mle_tuple : tuple of floats\n",
      " |          MLEs for any shape parameters (if applicable), followed by those\n",
      " |          for location and scale. For most random variables, shape statistics\n",
      " |          will be returned, but there are exceptions (e.g. ``norm``).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This fit is computed by maximizing a log-likelihood function, with\n",
      " |      penalty applied for samples outside of range of the distribution. The\n",
      " |      returned answer is not guaranteed to be the globally optimal MLE, it\n",
      " |      may only be locally optimal, or the optimization may fail altogether.\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Generate some data to fit: draw random variates from the `beta`\n",
      " |      distribution\n",
      " |      \n",
      " |      >>> from scipy.stats import beta\n",
      " |      >>> a, b = 1., 2.\n",
      " |      >>> x = beta.rvs(a, b, size=1000)\n",
      " |      \n",
      " |      Now we can fit all four parameters (``a``, ``b``, ``loc`` and ``scale``):\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x)\n",
      " |      \n",
      " |      We can also use some prior knowledge about the dataset: let's keep\n",
      " |      ``loc`` and ``scale`` fixed:\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x, floc=0, fscale=1)\n",
      " |      >>> loc1, scale1\n",
      " |      (0, 1)\n",
      " |      \n",
      " |      We can also keep shape parameters fixed by using ``f``-keywords. To\n",
      " |      keep the zero-th shape parameter ``a`` equal 1, use ``f0=1`` or,\n",
      " |      equivalently, ``fa=1``:\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x, fa=1, floc=0, fscale=1)\n",
      " |      >>> a1\n",
      " |      1\n",
      " |      \n",
      " |      Not all distributions return estimates for the shape parameters.\n",
      " |      ``norm`` for example just returns estimates for location and scale:\n",
      " |      \n",
      " |      >>> from scipy.stats import norm\n",
      " |      >>> x = norm.rvs(a, b, size=1000, random_state=123)\n",
      " |      >>> loc1, scale1 = norm.fit(x)\n",
      " |      >>> loc1, scale1\n",
      " |      (0.92087172783841631, 2.0015750750324668)\n",
      " |      \n",
      " |      This function (norm_gen.fit) uses explicit formulas for the maximum\n",
      " |      likelihood estimation of the parameters, so the `optimizer` argument\n",
      " |      is ignored.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.stats._distn_infrastructure.rv_continuous:\n",
      " |  \n",
      " |  __init__(self, momtype=1, a=None, b=None, xtol=1e-14, badvalue=None, name=None, longname=None, shapes=None, extradoc=None, seed=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  cdf(self, x, *args, **kwds)\n",
      " |      Cumulative distribution function of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cdf : ndarray\n",
      " |          Cumulative distribution function evaluated at `x`\n",
      " |  \n",
      " |  expect(self, func=None, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      " |      Calculate expected value of a function with respect to the\n",
      " |      distribution.\n",
      " |      \n",
      " |      The expected value of a function ``f(x)`` with respect to a\n",
      " |      distribution ``dist`` is defined as::\n",
      " |      \n",
      " |                  ubound\n",
      " |          E[x] = Integral(f(x) * dist.pdf(x))\n",
      " |                  lbound\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, optional\n",
      " |          Function for which integral is calculated. Takes only one argument.\n",
      " |          The default is the identity mapping f(x) = x.\n",
      " |      args : tuple, optional\n",
      " |          Shape parameters of the distribution.\n",
      " |      loc : float, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : float, optional\n",
      " |          Scale parameter (default=1).\n",
      " |      lb, ub : scalar, optional\n",
      " |          Lower and upper bound for integration. Default is set to the\n",
      " |          support of the distribution.\n",
      " |      conditional : bool, optional\n",
      " |          If True, the integral is corrected by the conditional probability\n",
      " |          of the integration interval.  The return value is the expectation\n",
      " |          of the function, conditional on being in the given interval.\n",
      " |          Default is False.\n",
      " |      \n",
      " |      Additional keyword arguments are passed to the integration routine.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      expect : float\n",
      " |          The calculated expected value.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The integration behavior of this function is inherited from\n",
      " |      `integrate.quad`.\n",
      " |  \n",
      " |  fit_loc_scale(self, data, *args)\n",
      " |      Estimate loc and scale parameters from data using 1st and 2nd moments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : array_like\n",
      " |          Data to fit.\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Lhat : float\n",
      " |          Estimated location parameter for the data.\n",
      " |      Shat : float\n",
      " |          Estimated scale parameter for the data.\n",
      " |  \n",
      " |  isf(self, q, *args, **kwds)\n",
      " |      Inverse survival function (inverse of `sf`) at q of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : array_like\n",
      " |          upper tail probability\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      x : ndarray or scalar\n",
      " |          Quantile corresponding to the upper tail probability q.\n",
      " |  \n",
      " |  logcdf(self, x, *args, **kwds)\n",
      " |      Log of the cumulative distribution function at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logcdf : array_like\n",
      " |          Log of the cumulative distribution function evaluated at x\n",
      " |  \n",
      " |  logpdf(self, x, *args, **kwds)\n",
      " |      Log of the probability density function at x of the given RV.\n",
      " |      \n",
      " |      This uses a more numerically accurate calculation if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logpdf : array_like\n",
      " |          Log of the probability density function evaluated at x\n",
      " |  \n",
      " |  logsf(self, x, *args, **kwds)\n",
      " |      Log of the survival function of the given RV.\n",
      " |      \n",
      " |      Returns the log of the \"survival function,\" defined as (1 - `cdf`),\n",
      " |      evaluated at `x`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logsf : ndarray\n",
      " |          Log of the survival function evaluated at `x`.\n",
      " |  \n",
      " |  nnlf(self, theta, x)\n",
      " |      Return negative loglikelihood function.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is ``-sum(log pdf(x, theta), axis=0)`` where `theta` are the\n",
      " |      parameters (including loc and scale).\n",
      " |  \n",
      " |  pdf(self, x, *args, **kwds)\n",
      " |      Probability density function at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pdf : ndarray\n",
      " |          Probability density function evaluated at x\n",
      " |  \n",
      " |  ppf(self, q, *args, **kwds)\n",
      " |      Percent point function (inverse of `cdf`) at q of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : array_like\n",
      " |          lower tail probability\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      x : array_like\n",
      " |          quantile corresponding to the lower tail probability q.\n",
      " |  \n",
      " |  sf(self, x, *args, **kwds)\n",
      " |      Survival function (1 - `cdf`) at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sf : array_like\n",
      " |          Survival function evaluated at x\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      " |  \n",
      " |  __call__(self, *args, **kwds)\n",
      " |      Freeze the distribution for the given arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution.  Should include all\n",
      " |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rv_frozen : rv_frozen instance\n",
      " |          The frozen distribution.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  entropy(self, *args, **kwds)\n",
      " |      Differential entropy of the RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : array_like, optional  (continuous distributions only).\n",
      " |          Scale parameter (default=1).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Entropy is defined base `e`:\n",
      " |      \n",
      " |      >>> drv = rv_discrete(values=((0, 1), (0.5, 0.5)))\n",
      " |      >>> np.allclose(drv.entropy(), np.log(2.0))\n",
      " |      True\n",
      " |  \n",
      " |  freeze(self, *args, **kwds)\n",
      " |      Freeze the distribution for the given arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution.  Should include all\n",
      " |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rv_frozen : rv_frozen instance\n",
      " |          The frozen distribution.\n",
      " |  \n",
      " |  interval(self, alpha, *args, **kwds)\n",
      " |      Confidence interval with equal areas around the median.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      alpha : array_like of float\n",
      " |          Probability that an rv will be drawn from the returned range.\n",
      " |          Each value should be in the range [0, 1].\n",
      " |      arg1, arg2, ... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          location parameter, Default is 0.\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter, Default is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a, b : ndarray of float\n",
      " |          end-points of range that contain ``100 * alpha %`` of the rv's\n",
      " |          possible values.\n",
      " |  \n",
      " |  mean(self, *args, **kwds)\n",
      " |      Mean of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : float\n",
      " |          the mean of the distribution\n",
      " |  \n",
      " |  median(self, *args, **kwds)\n",
      " |      Median of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter, Default is 0.\n",
      " |      scale : array_like, optional\n",
      " |          Scale parameter, Default is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : float\n",
      " |          The median of the distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      stats.distributions.rv_discrete.ppf\n",
      " |          Inverse of the CDF\n",
      " |  \n",
      " |  moment(self, n, *args, **kwds)\n",
      " |      n-th order non-central moment of distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, n >= 1\n",
      " |          Order of moment.\n",
      " |      arg1, arg2, arg3,... : float\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |  \n",
      " |  rvs(self, *args, **kwds)\n",
      " |      Random variates of given type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : array_like, optional\n",
      " |          Scale parameter (default=1).\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Defining number of random variates (default is 1).\n",
      " |      random_state : None or int or ``np.random.RandomState`` instance, optional\n",
      " |          If int or RandomState, use it for drawing the random variates.\n",
      " |          If None, rely on ``self.random_state``.\n",
      " |          Default is None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rvs : ndarray or scalar\n",
      " |          Random variates of given `size`.\n",
      " |  \n",
      " |  stats(self, *args, **kwds)\n",
      " |      Some statistics of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional (continuous RVs only)\n",
      " |          scale parameter (default=1)\n",
      " |      moments : str, optional\n",
      " |          composed of letters ['mvsk'] defining which moments to compute:\n",
      " |          'm' = mean,\n",
      " |          'v' = variance,\n",
      " |          's' = (Fisher's) skew,\n",
      " |          'k' = (Fisher's) kurtosis.\n",
      " |          (default is 'mv')\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stats : sequence\n",
      " |          of requested moments.\n",
      " |  \n",
      " |  std(self, *args, **kwds)\n",
      " |      Standard deviation of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : float\n",
      " |          standard deviation of the distribution\n",
      " |  \n",
      " |  var(self, *args, **kwds)\n",
      " |      Variance of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : float\n",
      " |          the variance of the distribution\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  random_state\n",
      " |      Get or set the RandomState object for generating random variates.\n",
      " |      \n",
      " |      This can be either None or an existing RandomState object.\n",
      " |      \n",
      " |      If None (or np.random), use the RandomState singleton used by np.random.\n",
      " |      If already a RandomState instance, use it.\n",
      " |      If an int, use a new RandomState instance seeded with seed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call up the doc for norm here:\n",
    "help(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__??????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Use the method that generates random variates to draw five samples from the standard normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(47)\n",
    "# draw five samples here\n",
    "samples = norm.rvs(loc=0, scale=1,size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ What is the mean of this sample? Is it exactly equal to the value you expected? Hint: the sample was drawn from the standard normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19355593334131074"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and print the mean here, hint: use np.mean()\n",
    "mean_samples = np.mean(samples)\n",
    "mean_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, the expected value of the mean of the standard normal distribution is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ What is the standard deviation of these numbers? Calculate this manually here as $\\sqrt{\\frac{\\sum_i(x_i - \\bar{x})^2}{n}}$. Hint: np.sqrt() and np.sum() will be useful here and remember that numpy supports [broadcasting](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96061956394786407"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((samples-mean_samples)**2)/len(samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96061956394786407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have calculated the actual standard deviation of a small (size 5) data set. But in this case, this small data set is actually a sample from our larger (infinite) population. The population in this case is infinite because we could keep drawing our normal random variates until our computers died.\n",
    "\n",
    "__Q:__ If all we had to go on was our five samples, what would be our best estimate of the population standard deviation? This is where we use Bessel's correction (the $n-1$ in the denominator), thus $\\sqrt{\\frac{\\sum_i(x_i - \\bar{x})^2}{n-1}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0740053227518152"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((samples-mean_samples)**2)/(len(samples)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Now use numpy's std function to calculate the standard deviation of our random samples. Which of the above standard deviations did it return?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96061956394786407"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Consult the documentation for np.std() to see how to apply the correction for estimating the population parameter and verify this produces the expected result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use the ssof (degrees of freedom argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0740053227518152"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(samples,ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you've been introduced to the scipy.stats package and used it to draw a small sample from the standard normal distribution. You've calculated the average (the mean) of this sample and seen that this is not exactly equal to the expected population parameter (which we know because we're generating the random variates from a specific, known distribution). You've been introduced to two ways of calculating the standard deviation; one uses $n$ in the denominator and the other uses $n-1$ (Bessel's correction). You've also seen which of these calculations np.std() performs by default and how to get it to generate the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You use $n$ as the denominator if you want to calculate the standard deviation of a sequence of numbers. You use $n-1$ if you are using this sequence of numbers to estimate the population parameter. This brings us to some terminology that can be a little confusing.\n",
    "\n",
    "The population parameter is traditionally written as $\\sigma$ and the sample statistic as $s$. Rather unhelpfully, $s$ is also called the sample standard deviation (using $n-1$) whereas the standard deviation of the sample uses $n$. You've read that correctly â€” we have the sample standard deviation and the standard deviation of the sample and they're not the same thing! \n",
    "\n",
    "The sample standard deviation\n",
    "\\begin{equation}\n",
    "s = \\sqrt{\\frac{\\sum_i(x_i - \\bar{x})^2}{n-1}} \\approx \\sigma,\n",
    "\\end{equation}\n",
    "is our best (unbiased) estimate of the population parameter ($\\sigma$).\n",
    "\n",
    "If your data set _is_ your entire population, you simply want to calculate the population parameter, $\\sigma$, via\n",
    "\\begin{equation}\n",
    "\\sigma = \\sqrt{\\frac{\\sum_i(x_i - \\bar{x})^2}{n}}\n",
    "\\end{equation}\n",
    "as you have complete, full knowledge of your population. In other words, your sample _is_ your population. It's worth noting at this point if your sample is your population then you know absolutely everything about your population, there are no probabilities really to calculate and no inference to be done.\n",
    "\n",
    "If, however, you have sampled _from_ your population, you only have partial knowledge of the state of your population and the standard deviation of your sample is not an unbiased estimate of the standard deviation of the population, in which case you can estimate that population parameter via the sample standard deviation, which uses the $n-1$ denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're now firmly in frequentist theory territory. Great work so far! Now let's dive deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II Sampling distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been dealing with the concept of taking a sample from a population to infer the population parameters. One statistic we calculated for a sample was the mean. As our samples will be expected to vary from one draw to another, so will our sample statistics. If we were to perform repeat draws of size $n$ and calculate the mean of each, we would expect to obtain a distribution of values. This is the sampling distribution of the mean. The Central Limit Theorem (CLT) tells us that such a distribution will approach a normal distribution as $n$ increases. For the sampling distribution of the mean, the standard deviation of this distribution is given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_{mean} = \\frac{\\sigma}{\\sqrt n}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\sigma_{mean}$ is the standard deviation of the sampling distribution of the mean and $\\sigma$ is the standard deviation of the population (the population parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is important because typically we are dealing with samples from populations and all we know about the population is what we have in the sample. From this sample we wish to make inferences about the population. We may do this, for example, by looking at the histogram of the values and by calculating the mean and standard deviation (as estimates of the population parameters), and so we are intrinsically interested in how these quantities vary across samples. In other words, having taken one sample of size $n$ and made some claims about the general population, what if we were to take another sample of size $n$? Would we get the same result? Would we make the same claims about the general population? This brings us to a fundamental question: _when we make some inference about a population based on our sample, how confident can we be that we've got it 'right'?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give our normal distribution a little flavor. Also, for didactic purposes, the standard normal distribution, with its variance equal to its standard deviation of one would not be a great illustration of a key point. Let us imagine we live in a town of 50000 people and we know the height of everyone in this town. We will have 50000 numbers that tell us everything about our population. We'll simulate these numbers now and put ourselves in one particular town, called 'town 47', where the population mean height is 172 cm and population standard deviation is 5 cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(47)\n",
    "pop_heights = norm.rvs(172, 5, size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(pop_heights, bins=30)\n",
    "_ = plt.xlabel('height (cm)')\n",
    "_ = plt.ylabel('number of people')\n",
    "_ = plt.title('Distribution of heights in entire town population')\n",
    "_ = plt.axvline(172, color='r')\n",
    "_ = plt.axvline(172+5, color='r', linestyle='--')\n",
    "_ = plt.axvline(172-5, color='r', linestyle='--')\n",
    "_ = plt.axvline(172+10, color='r', linestyle='-.')\n",
    "_ = plt.axvline(172-10, color='r', linestyle='-.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, 50000 people is rather a lot to chase after with a tape measure. If all you want to know is the average height of the townsfolk, then can you just go out and measure a sample to get a pretty good estimate of the average height?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def townsfolk_sampler(n):\n",
    "    return np.random.choice(pop_heights, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you go out one day and randomly sample 10 people to measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(47)\n",
    "daily_sample1 = townsfolk_sampler(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(daily_sample1, bins=10)\n",
    "_ = plt.xlabel('height (cm)')\n",
    "_ = plt.ylabel('number of people')\n",
    "_ = plt.title('Distribution of heights in sample size 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample distribution doesn't look much like what we know (but wouldn't know in real-life) the population distribution looks like. What do we get for the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.47911444163503"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(daily_sample1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we went out and repeated this experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_sample2 = townsfolk_sampler(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.7317666636263"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(daily_sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Simulate performing this random trial every day for a year, calculating the mean of each daily sample of 10, and plot the resultant sampling distribution of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(47)\n",
    "# take your samples here\n",
    "yearly_sample = [] \n",
    "for i in range(365):\n",
    "    daily_sample3 = townsfolk_sampler(10)\n",
    "    mean_daily_sample3 = np.mean(daily_sample3)\n",
    "    yearly_sample.append(mean_daily_sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f027136940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(yearly_sample, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is the distribution of the means of samples of size 10 taken from our population. The Central Limit Theorem tells us the expected mean of this distribution will be equal to the population mean, and standard deviation will be $\\sigma / \\sqrt n$, which, in this case, should be approximately 1.58."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Verify the above results from the CLT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171.86600493586491"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(yearly_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.01926024258449"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pop_heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yearly_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, here we knew our population parameters, that the average height really is 172 cm and the standard deviation 5 cm, and we see some of our daily estimates of the population mean were as low as around 168 and some as high as 176."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Repeat the above year's worth of samples but for a sample size of 50 (perhaps you had a bigger budget for conducting surveys that year!) Would you expect your distribution of sample means to be wider (more variable) or narrower (more consistent)? Compare your resultant summary statistics to those predicted by the CLT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std: 0.674535408845 Mean: 171.943660809\n"
     ]
    }
   ],
   "source": [
    "seed(47)\n",
    "# calculate daily means from the larger sample size here\n",
    "yearly_sample_2 = [] \n",
    "for i in range(365):\n",
    "    daily_sample4 = townsfolk_sampler(50)\n",
    "    mean_daily_sample4 = np.mean(daily_sample4)\n",
    "    yearly_sample_2.append(mean_daily_sample4)\n",
    "\n",
    "print('std: ' + str(np.std(yearly_sample_2, ddof=1)) + ' Mean: ' + str (np.mean(yearly_sample_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we've seen so far, then, is that we can estimate population parameters from a sample from the population, and that samples have their own distributions. Furthermore, the larger the sample size, the narrower are those sampling distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III Normally testing times!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the above is well and good. We've been sampling from a population we know is normally distributed, we've come to understand when to use $n$ and when to use $n-1$ in the denominator to calculate the spread of a distribution, and we've  seen the Central Limit Theorem in action for a sampling distribution. All seems very well behaved in Frequentist land. But, well, why should you really care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, you'll rarely (if ever) actually know your population parameters, but you still have to estimate them somehow. If you want to make inferences such as \"is this observation unusual?\" or \"has my population mean changed?\" then you need to have some idea what the underlying distribution is so you can calculate relevant probabilities. In Frequentist inference, you use the formulas as above to deduce these population parameters. Take a moment in the next part of this assignment to refresh your understanding of how these probabilities work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall some of the basic properties of the standard Normal distribution, such as about 68% of observations being within plus or minus 1 standard deviation of the mean.\n",
    "\n",
    "__Q:__ Using this fact, calculate the probability of observing the value 1 or less in a single observation from the standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400000000000001"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = 0.68 + (0.32/2)\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating this probability involved calculating the area under the pdf from the value of 1 and below. To put it another way, we need to integrate the pdf. We could just add together the known areas of chunks (from -Inf to 0 and then 0 to $+\\sigma$ in the example above. One way to do this is using look up tables (literally). Fortunately, scipy has this functionality built in with the cdf() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Use the cdf() function to answer the question above again and verify you get the same answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84134474606854293"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf(x=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Using our knowledge of the population parameters for our townsfolk's heights, what is the probability of selecting one person at random and their height being 177 cm or less? Calculate this using both of the approaches given above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84134474606854293"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf(177,loc=172, scale=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400000000000001"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = 0.68 + (0.32/2)\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Turning this question around. Let's say we randomly pick one person and measure their height and find they are 2.00 m tall? How surprised should we be at this result, given what we know about the population distribution? In other words, how likely would it be to obtain a value at least as extreme as this? Express this as a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0717590259723409e-08"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (norm.cdf(200, loc=172, scale=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very unlikely given the above probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could calculate this probability by virtue of knowing the population parameters. We were then able to use the known properties of the relevant normal distribution to calculate the probability of observing a value at least as extreme as our test value. We have essentially just performed a z-test (albeit without having prespecified a threshold for our \"level of surprise\")!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're about to come to a pinch, though here. We've said a couple of times that we rarely, if ever, know the true population parameters; we have to estimate them from our sample and we cannot even begin to estimate the standard deviation from a single observation. This is very true and usually we have sample sizes larger than one. This means we can calculate the mean of the sample as our best estimate of the population mean and the standard deviation (careful now! which one?) as our best estimate of the population standard deviation. In other words, we are now coming to deal with the sampling distributions we mentioned above as we are generally concerned with the properties of the sample means we obtain.\n",
    "\n",
    "Above, we highlighted one result from the CLT, whereby the sampling distribution (of the mean) becomes narrower and narrower with the square root of the sample size. We remind ourselves that another result from the CLT is that _even if the underlying population distribution is not normal, the sampling distribution will tend to become normal with sufficiently large sample size_. This is the key driver for us 'requiring' a certain sample size, for example you may frequently see a minimum sample size of 30 stated in many places. In reality this is simply a rule of thumb; if the underlying distribution is approximately normal then your sampling distribution will already be pretty normal, but if the underlying distribution is heavily skewed then you'd want to increase your sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Let's now start from the position of knowing nothing about the heights of people in our town.\n",
    "* Use our favorite random seed of 47, to randomly sample the heights of 50 townsfolk\n",
    "* Estimate the population mean using np.mean\n",
    "* Estimate the population standard deviation using np.std (remember which denominator to use!)\n",
    "* Calculate the (95%) [margin of error](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/hypothesis-testing/margin-of-error/#WhatMofE) (use the exact critial z value to 2 decimal places - [look this up](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/find-critical-values/) or use norm.ppf())\n",
    "* Calculate the 95% Confidence Interval of the mean\n",
    "* Does this interval include the true population mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(47)\n",
    "# take your sample now\n",
    "samp_50 = np.random.choice(pop_heights,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.7815108576788"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(samp_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1954243644335474"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(samp_50, ddof = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9010535370567423"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Margin_Of_Error = 1.6449 * (np.std(samp_50, ddof = 1))\n",
    "Margin_Of_Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165.880457321,179.682564395)\n"
     ]
    }
   ],
   "source": [
    "print('(' + str(np.mean(samp_50)-Margin_Of_Error) + ',' + str(np.mean(samp_50)+Margin_Of_Error) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "It does include the true population mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Above, you calculated the confidence interval using the critical z value. What is the problem with this? What requirement, or requirements, are we (strictly) failing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Calculate the 95% confidence interval for the mean using the _t_ distribution. Is this wider or narrower than that based on the normal distribution above? If you're unsure, you may find this [resource](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/confidence-interval/) useful. For calculating the critical value, remember how you could calculate this for the normal distribution using norm.ppf()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.4286075481469958"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Margin_Of_Error_t = 2.009 * (np.std(samp_50, ddof = 1))\n",
    "Margin_Of_Error_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164.35290331,181.210118406)\n"
     ]
    }
   ],
   "source": [
    "print('(' + str(np.mean(samp_50)-Margin_Of_Error_t) + ',' + str(np.mean(samp_50)+Margin_Of_Error_t) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly wider than the previous confidence interval. This reflects the greater uncertainty given that we are estimating population parameters from a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having completed this project notebook, you now have hands-on experience:\n",
    "* sampling and calculating probabilities from a normal distribution\n",
    "* the correct way to estimate the standard deviation of a population (the population parameter) from a sample\n",
    "* what a sampling distribution is and how the Central Limit Theorem applies\n",
    "* how to calculate critical values and confidence intervals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
